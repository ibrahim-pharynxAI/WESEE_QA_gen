## 2.6 Structural block diagram

To clarify the proposed architecture, we have included a structural block diagram visualizing the sequence of operations, focusing on the activation and pooling layers. The diagram (refer Fig. 4) shows the flow of data starting with convolution, which extracts features from the input. These features are processed through positive ReLU (PosReLU) and negative ReLU (NegReLU) functions, resulting in distinct feature maps for each type of activation. The feature maps are then concatenated block-wise, preserving both positive and negative activations for further processing, thus providing a richer feature representation. Subsequently, MaxPooling and MinPooling layers are applied separately to emphasize high- and low-intensity features, respectively. The outputs are concatenated in an interleaved manner, ensuring balanced feature preservation and enabling the model to capture a comprehensive range of patterns, thereby improving nuanced learning. The MaxMinPooling output is then further passed through the subsequent blocks of the model.
