## 1 Introduction

The convolutional neural networks (CNNs) represent a significant innovation in deep learning, designed to address the complexities of image classification [1, 2]. Inspired by the structure of the human visual cortex, CNNs mimic the hierarchical processing of visual information, allowing them to manage spatial hierarchies in data effectively. This architecture is particularly suited for analyzing and interpreting visual imagery across various applications, making CNNs exceptionally effective for these tasks [3].

&amp; Pushpendra Singh spushp@jnu.ac.in

Narendra Kumar Mishra eez188568@ee.iitd.ac.in

Anubha Gupta anubha@iiitd.ac.in

Shiv Dutt Joshi sdjoshi@iitd.ac.in

- 1 Department of Electrical Engineering, IIT Delhi, Delhi, India
- 2 School of Engineering, Jawaharlal Nehru University, Delhi, India
- 3 SBILab, Department of ECE, IIT-Delhi, Delhi, India

CNNs have become foundational in computer vision because they can automate feature extraction. Unlike traditional image processing techniques that require manual feature selection and careful engineering, CNNs learn to identify relevant features directly from the data. This capability has revolutionized image classification, enabling substantial advancements in object recognition, video, and medical image analysis. By learning to detect features from training data, CNNs have significantly improved the accuracy and efficiency of image classification tasks [4].

Recent advancements in medical image classification have demonstrated the effectiveness of CNN-based architectures for diagnosing various diseases. Akyol [5] introduced a two-stage voting framework for COVID-19 detection, while Kurt et al. [6] applied EfficientNet models for analyzing lung parenchyma to detect COVID-19, achieving promising results. Kibriya and Amin [7] further

<!-- image -->

enhanced COVID-19 detection with a residual networkbased framework using chest X-ray images. Additionally, CNN models have also been widely applied for cancer detection. Sahu et al. [8] proposed a hybrid CNN classifier for breast cancer detection using mammogram and ultrasound datasets, achieving high classification accuracy. Mridha et al. [9] tackled skin cancer classification with explainable AI models, employing optimized CNN architectures for interpretability. Diabetic retinopathy detection using deep learning ensemble approaches has also shown significant promise, as demonstrated by Qummar et al. [10]. Furthermore, Oguz et al. [11] developed a CNNbased hybrid model to detect glaucoma disease from medical images effectively, showcasing the broad applicability of CNNs across various medical image classification tasks.

CNNs are distinguished by their deep architecture, which consists of several layers of fundamental building blocks arranged in various patterns. The core components of a CNN, illustrated in Fig. 1, are each designed to process different aspects of input data [12]. These layers work in tandem to extract and refine features, enabling the network to perform complex image analysis tasks effectively. The convolutional layers apply filters to the input, creating feature maps highlighting key patterns. The activation layers like ReLU introduce nonlinearity, enabling the model to learn complex data relationships. The pooling layers reduce spatial dimensions, improving efficiency while retaining important features. In the final stages, the dense layers interpret high-level features and produce predictions, with the softmax layer converting outputs into class probabilities. The output layer delivers the final classification, such as distinguishing COVID-19, normal, and pneumonia.

Recognizing the limitations of MaxPooling, especially its tendency to overlook less dominant features, there is a strong impetus to explore novel pooling strategies that preserve a more comprehensive set of information, thus potentially enhancing the overall performance of the network. Recent research underscores the potential benefits of utilizing diverse pooling strategies, including better generalization capabilities of networks from training datasets to unseen data [16-18], eventually enhancing their performance and applicability in real-world applications. For example, MinPooling captures the minimum values within the receptive field, which can be critical in scenarios where these lesser values contain important contrasts or details, such as images with subtle variations in shading or lighting. An innovative solution to leverage the strengths of both MaxPooling and MinPooling is the development of MaxMinPooling. This approach integrates outputs from both pooling strategies, preserving the highest and lowest values in the feature map. Such integration ensures that no critical details are overlooked, providing a balanced and detailed representation of the image data.

In traditional CNNs, MaxPooling is a widely utilized technique that processes the input by extracting the maximum value from each segment of an image covered by the kernel [13]. While MaxPooling effectively highlights the most prominent features, it can result in the loss of potentially important details [14]. This loss is particularly significant in fields like medical imaging, where every pixel may carry crucial diagnostic information [15].

Jun Park et al. [19] introduced conditional MinPooling (CMP) to enhance CNN feature representation by preserving critical features through a tolerance mechanism. Their approach restructures CNNs by combining CMP with MaxPooling and applying a 1 /C2 1 convolution to reduce channel dimensions before pooling. This technique captures diverse features and improves robustness. Evaluated on Caltech 101 and custom datasets, CMP increased accuracy by 0.16 /C0 0.52% and decreased loss by 19.98 /C0 28.71% compared to traditional methods. Vienken, in his master thesis [20], proposed to enhance the efficiency of CNNs through multi-scale convolution filters and MinMaxPooling. This approach captures key features while being noise-resistant, addressing the computational complexity of deeper CNNs. Experiments showed that the MinMax method improved accuracy by 0.71% on CIFAR10 and 4.9% on the Places dataset compared to the traditional methods.

One innovative approach, presented by Ozdemir, is the Avg-TopK pooling method that computes the weighted average of the most significant features by focusing on the

Fig. 1 Architecture of a typical CNN model

<!-- image -->

top K amplitude pixels [21]. Zhao et al. further modified this pooling strategy and introduced T-Max-Avg pool layer, which allows flexibility in feature extraction by using a threshold parameter to select the most representational/ interactive pixels, enabling the maximum value or the weighted average of the top pixels to be pooled via threshold T based on data characteristics [18].

Further studies include Yu et al.'s mixed pooling method, which introduces variability by alternating between MaxPooling and average pooling in a stochastic manner, thereby enhancing regularization [22]. Er et al. have developed an attention pooling scheme that uses outputs from a bidirectional LSTM as a reference to weigh features extracted by convolutional layers, ensuring that critical information is preserved during the pooling process [23]. Cui et al. have proposed a general kernel pooling framework that leverages higher-order interactions of features through kernel approximations like the Gaussian RBF, thus capturing more complex patterns without extensive parameterization [24]. Williams et al. introduced wavelet pooling, which employs a multi-level decomposition strategy to refine feature processing by discarding less critical subbands, thus focusing on more relevant data [25].

Jie et al. explored dynamic pooling with their RunPool layer, which adapts the pooling operation dynamically to suit the training data's demands better [26]. Lastly, Sharma et al. introduced a novel method using fuzzy logic to perform dimension reduction, effectively shrinking the spatial size of convolved features while retaining essential information [27]. In a comprehensive review, Nirthika et al. discuss various pooling techniques across computer vision and medical image analysis, highlighting the breadth of research and the potential for these methods to improve CNN performance [28].

Piyush Satti et al. [29] designed a MinMax average pooling-based filter for effectively removing salt and pepper noise from images. This method combines Max- and MinPooling to better preserve edges and enhance the peak signal-to-noise ratio (PSNR), particularly in medical images corrupted by medium to high noise densities. Another study by Liyanage et al. [30] focused on hyperspectral image band selection and utilized various pooling methods, including Max- and average pooling, to reduce spectral dimensionality while retaining crucial spectral information. This method enhances classification accuracy and efficiency by addressing the limitations of traditional MaxPooling, ensuring the preservation of essential spectral details. Prior literature work is summarized in Table 1.

Motivated by the above discussion, this study aims to significantly enhance the performance of CNN-based models for image classification through innovative architectural enhancements. We aim to address the limitations of traditional CNN models by introducing refined pooling strategies that improve the accuracy and robustness of classification in various imaging contexts. The significant contributions of the study are as follows:

- 1) Novel MaxMinPooling Architecture with Dual-Activation Function Approach: We have developed an innovative pooling architecture within the traditional CNN framework, termed MaxMinPooling. This architecture enhances feature extraction by uniquely combining the outputs from MaxPooling and MinPooling layers through interleaving, effectively merging the most and least activated pixels from the feature map. This method enriches the input for subsequent layers, improving the model's ability to capture detailed and nuanced features essential for accurate classification.
- 2) To enhance the effectiveness of the MaxMinPooling layer, we incorporate both positive ReLU max ð 0 ; x Þ and Negative ReLU min ð 0 ; x Þ activation functions and concatenate their outputs within the CNN architecture. This inclusion allows the layer to retain significant positive and negative features, ensuring a more comprehensive and nuanced feature representation. The dual-activation approach captures a broader range of data characteristics, which is essential for high-fidelity applications in image analysis, such as precise medical diagnostics and other complex imaging tasks.
- 3) Fusion of Probabilistic Outputs: We have integrated the probabilistic outputs from three specialized CNN architectures-each characterized by a distinct pooling layer: MaxPooling, MinPooling, and MaxMinPooling. By averaging these probabilities, we harness the diverse strengths of each pooling method, which enhances the overall stability and accuracy of the model. This ensembling effectively mitigates the weaknesses of individual architectures, leading to superior performance and better generalizability of the architecture across various datasets.
- 4) Comprehensive Performance Evaluation: The efficacy of the proposed model is demonstrated through a comprehensive evaluation across on four diverse datasets. We assess the model's performance on standard benchmark datasets like CIFAR-10 and CIFAR-100, as well as on specialized medical imaging datasets, including X-rays and CT scans for the detection of COVID-19 disease [31]. The CIFAR datasets were selected due to their widespread use in benchmarking image classification models, providing a reliable measure of the performance of the model against established standards. The inclusion of CT scan and X-ray images addresses the urgent need for automated tools in managing the

Table 1 Summary of recent pooling techniques used in CNNs. Each method is evaluated on different datasets, highlighting the key features of the pooling strategy and corresponding specific benefits. The symbols " and # represent an increase and a decrease, respectively

| Study                    | Pooling method               | Key features                                                                      | Dataset(s)                   | Remarks                                            |
|--------------------------|------------------------------|-----------------------------------------------------------------------------------|------------------------------|----------------------------------------------------|
| Jun Park et al. [19]     | Conditional MinPooling (CMP) | Combines CMP and MaxPooling with 1 /C2 1 convolution for dimensionality reduction | Caltech 101, Custom datasets | Accuracy " 0.16 /C0 0.52%, Loss # 19.98 /C0 28.71% |
| Vienken [20]             | MinmaxPooling                | Multi-scale convolution with MinMaxPooling                                        | CIFAR-10, Places dataset     | Accuracy " 0.71% (CIFAR-10), " 4.9% (Places)       |
| Ozdemir [21]             | Avg-topk pooling             | Weighted average of significant features                                          | Image datasets               | Accuracy " 16.62% (CIFAR- 10), " 25% (CIFAR-100)   |
| Zhao et al. [18]         | T-max-avg pooling            | Threshold-based selective feature extraction                                      | ImageNet, Custom datasets    | Adaptive pooling flexibility                       |
| Yu et al. [22]           | Mixed pooling                | Alternates between Max- and average pooling                                       | CIFAR-100, ImageNet          | Enhanced regularization                            |
| Er et al. [23]           | Attention pooling            | LSTM-weighted feature extraction                                                  | Medical image datasets       | Preserves critical information                     |
| Cui et al. [24]          | Kernel pooling               | Higher-order interactions using kernel approximations                             | CIFAR-10, ImageNet           | Captures complex patterns                          |
| Williams et al. [25]     | Wavelet pooling              | Multi-level decomposition, discards less critical subbands                        | ImageNet, Medical images     | Refines feature selection                          |
| Jie et al. [26]          | RunPool                      | Dynamic pooling adapts to data demands                                            | CIFAR-10, MNIST              | Data-adaptive pooling                              |
| Sharma et al. [27]       | Fuzzy logic pooling          | Dimension reduction using fuzzy logic                                             | Medical image datasets       | Retains essential spatial information              |
| Piyush Satti et al. [29] | MinMax average pooling       | Removes salt and pepper noise                                                     | Medical images               | PSNR enhancement, noise reduction                  |
| Liyanage et al. [30]     | Max- and average pooling     | Reduces spectral dimensionality, preserves spectral details                       | Hyperspectral images         | Classification accuracy " by 2.53%                 |

COVID-19 pandemic, demonstrating the applicability of the model in critical real-world scenarios. This diverse selection of datasets effectively showcases the generalizability and robustness of the proposed method, proving its efficacy across both standard and specialized image classification tasks.
